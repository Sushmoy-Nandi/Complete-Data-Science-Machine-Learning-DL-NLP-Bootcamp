{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c36a58",
   "metadata": {},
   "source": [
    "# Performance Metrics: R Squared and Adjusted R Squared\n",
    "\n",
    "## Commands\n",
    "\n",
    "* `R² = 1 - (SS_residual / SS_total)`\n",
    "* `R² = 1 - sum((y_i - y_hat_i)^2) / sum((y_i - y_avg)^2)`\n",
    "* `R²_adjusted = 1 - (1 - R²) * ((N - 1) / (N - P - 1))`\n",
    "\n",
    "## Summary\n",
    "\n",
    "* **Performance metrics** such as **R Squared ($R^2$)** and **Adjusted R Squared** are essential for determining the quality of a linear regression model.\n",
    "* **R Squared** calculates accuracy by comparing the sum of squared residuals (errors) against the sum of squared totals (variance from the mean).\n",
    "* A major limitation of **R Squared** is that it tends to increase whenever new features are added, even if those features are **uncorrelated** or irrelevant to the output.\n",
    "* **Adjusted R Squared** solves this problem by penalizing the addition of independent features that do not correlate with the target variable, decreasing the score if the new feature is not useful.\n",
    "\n",
    "---\n",
    "\n",
    "## R Squared ($R^2$)\n",
    "\n",
    "**R Squared** is a statistical metric used to measure how close the data are to the fitted regression line. It is defined by the following formula:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{residual}}{SS_{total}}\n",
    "$$\n",
    "\n",
    "### Understanding the Components\n",
    "\n",
    "1. **Sum of Squares Residual ($SS_{residual}$)**:\n",
    "   * This represents the sum of the squared differences between the **true output** ($y_i$) and the **predicted output** ($\\hat{y}_i$).\n",
    "   * Visually, this is the distance between the actual data points and the **best fit line**.\n",
    "   * Formula:\n",
    "     $$\n",
    "     \\sum (y_i - \\hat{y}_i)^2\n",
    "     $$\n",
    "\n",
    "2. **Sum of Squares Total ($SS_{total}$)**:\n",
    "   * This represents the sum of the squared differences between the **true output** ($y_i$) and the **average of all true outputs** ($\\bar{y_i}$).\n",
    "   * Visually, this compares the data points to a simple average line (mean) rather than the best fit line.\n",
    "   * Formula:\n",
    "     $$\n",
    "     \\sum (y_i - \\bar{y_i})^2\n",
    "     $$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "* Since the **best fit line** minimizes error, $SS_{residual}$ is typically smaller than $SS_{total}$.\n",
    "* Dividing a smaller number by a larger number gives a small value; subtracting this from 1 yields a value close to 1.\n",
    "* **Accuracy**: An $R^2$ value of 0.70 implies **70% accuracy**, while 0.90 implies **90% accuracy**.\n",
    "* The closer the value is to 1, the **more accurate** the model is considered to be.\n",
    "\n",
    "## The Problem with R Squared\n",
    "\n",
    "While **R Squared** is a useful metric, it has a significant flaw when dealing with **multiple linear regression**.\n",
    "\n",
    "### Scenario: Adding Correlated Features\n",
    "\n",
    "* A feature like **Size of House** is positively correlated with **Price**, and a model might yield an $R^2$ of **75%**.\n",
    "* Adding another relevant feature, such as **Number of Bedrooms**, typically increases the $R^2$ (e.g., to **80%**) because it provides more predictive power.\n",
    "\n",
    "### Scenario: Adding Uncorrelated Features\n",
    "\n",
    "* Adding an irrelevant feature, such as **Gender**, which has **no correlation** with house price, will often still increase or maintain the $R^2$ value (e.g., **87%**).\n",
    "* **Mathematical Reason**: The formula structure ensures that adding variables usually reduces residual error slightly, even if the variable is noise.\n",
    "* **Conclusion**: $R^2$ is unreliable for feature selection because it does not penalize useless variables.\n",
    "\n",
    "## Adjusted R Squared\n",
    "\n",
    "**Adjusted R Squared** is an improved metric that accounts for the number of predictors in the model. It penalizes the model for adding features that do not improve performance meaningfully.\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$\n",
    "R^2_{adjusted} = 1 - (1 - R^2)\\frac{N - 1}{N - P - 1}\n",
    "$$\n",
    "\n",
    "### Variables\n",
    "\n",
    "* **$R^2$**: The R Squared value of the model\n",
    "* **$N$**: Number of data points\n",
    "* **$P$**: Number of independent features (predictors)\n",
    "\n",
    "### Behavior Comparison\n",
    "\n",
    "1. **Adding an Irrelevant Feature**:\n",
    "   * Increasing $P$ decreases the denominator $(N - P - 1)$.\n",
    "   * If $R^2$ does not increase significantly, Adjusted $R^2$ **decreases**.\n",
    "\n",
    "2. **Adding a Relevant Feature**:\n",
    "   * A strong increase in $R^2$ outweighs the penalty for increasing $P$.\n",
    "   * Adjusted $R^2$ **increases**, correctly reflecting improved model quality.\n",
    "\n",
    "This mechanism ensures that **Adjusted R Squared** only increases when a new feature truly improves the model beyond chance.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
